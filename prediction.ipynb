{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install absl-py==2.1.0 astunparse==1.6.3 certifi==2024.12.14 charset-normalizer==3.4.0 flatbuffers==24.3.25 gast==0.6.0 google-pasta==0.2.0 grpcio==1.68.1 h5py==3.12.1 idna==3.10 keras==3.5.0 libclang==18.1.1 Markdown==3.7 markdown-it-py==3.0.0 MarkupSafe==3.0.2 mdurl==0.1.2 ml-dtypes==0.4.1 namex==0.0.8 numpy==1.26.4 opt_einsum==3.4.0 optree==0.13.1 packaging==24.2 protobuf==4.25.5 Pygments==2.18.0 requests==2.32.3 rich==13.9.4 setuptools==75.6.0 six==1.17.0 tensorboard==2.17.1 tensorboard-data-server==0.7.2 tensorflow==2.17.0  termcolor==2.5.0 typing_extensions==4.12.2 urllib3==2.2.3 Werkzeug==3.1.3 wheel==0.45.1 wrapt==1.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mtcnn[tensorflow]\n",
      "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting joblib>=1.4.2 (from mtcnn[tensorflow])\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting lz4>=4.3.3 (from mtcnn[tensorflow])\n",
      "  Downloading lz4-4.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tensorflow>=2.12.0 (from mtcnn[tensorflow])\n",
      "  Downloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /home/salaar/anaconda3/envs/llm_finetune/lib/python3.10/site-packages (from tensorflow>=2.12.0->mtcnn[tensorflow]) (25.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: setuptools in /home/salaar/anaconda3/envs/llm_finetune/lib/python3.10/site-packages (from tensorflow>=2.12.0->mtcnn[tensorflow]) (78.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/salaar/anaconda3/envs/llm_finetune/lib/python3.10/site-packages (from tensorflow>=2.12.0->mtcnn[tensorflow]) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/salaar/anaconda3/envs/llm_finetune/lib/python3.10/site-packages (from tensorflow>=2.12.0->mtcnn[tensorflow]) (4.14.1)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Downloading grpcio-1.74.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Using cached keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Downloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Downloading h5py-3.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Downloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Downloading charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Downloading certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Using cached markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/salaar/anaconda3/envs/llm_finetune/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.12.0->mtcnn[tensorflow]) (0.45.1)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Downloading optree-0.17.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/salaar/anaconda3/envs/llm_finetune/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow>=2.12.0->mtcnn[tensorflow]) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.12.0->mtcnn[tensorflow])\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m940.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m980.5 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading lz4-4.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.8/644.8 MB\u001b[0m \u001b[31m944.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:13\u001b[0mm\n",
      "\u001b[?25hDownloading grpcio-1.74.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m77.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m78.7 kB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0mm\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:02\u001b[0m0m\n",
      "\u001b[?25hDownloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Using cached markdown-3.8.2-py3-none-any.whl (106 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (387 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, urllib3, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, MarkupSafe, markdown, lz4, joblib, idna, grpcio, google-pasta, gast, charset_normalizer, certifi, astunparse, absl-py, werkzeug, requests, mtcnn, ml-dtypes, markdown-it-py, h5py, tensorboard, rich, keras, tensorflow\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35/35\u001b[0m [tensorflow]237m━\u001b[0m \u001b[32m34/35\u001b[0m [tensorflow]]rver]-filesystem]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 absl-py-2.3.1 astunparse-1.6.3 certifi-2025.7.14 charset_normalizer-3.4.2 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.74.0 h5py-3.14.0 idna-3.10 joblib-1.5.1 keras-3.10.0 libclang-18.1.1 lz4-4.4.4 markdown-3.8.2 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 mtcnn-1.0.0 namex-0.1.0 numpy-2.1.3 opt-einsum-3.4.0 optree-0.17.0 protobuf-5.29.5 requests-2.32.4 rich-14.1.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.1.0 urllib3-2.5.0 werkzeug-3.1.3 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install mtcnn[tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in /home/salaar/anaconda3/envs/llm_finetune/lib/python3.10/site-packages (from opencv-python) (2.1.3)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.12.0.88\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Pillow\n",
      "  Downloading pillow-11.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Downloading pillow-11.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Pillow\n",
      "Successfully installed Pillow-11.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 14:18:05.850666: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753780685.866166  299004 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753780685.870730  299004 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753780685.882606  299004 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753780685.882626  299004 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753780685.882628  299004 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753780685.882629  299004 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-29 14:18:05.886580: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "\n",
    "# Import MTCNN for face detection\n",
    "from mtcnn import MTCNN\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "TIME_STEPS = 30  # Number of frames per video\n",
    "HEIGHT, WIDTH = 299, 299\n",
    "\n",
    "# Paths\n",
    "model_path = 'backend/ml_models/XceptionNet.keras'  # Update with your model path\n",
    "# video_path = '/content/drive/MyDrive/Dataset DDM/Saved models_trial 1/demo 2.mp4'  # Update with your video path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1753780700.068059  299004 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "def build_model(lstm_hidden_size=256, num_classes=2, dropout_rate=0.5):\n",
    "    # Input shape: (batch_size, TIME_STEPS, HEIGHT, WIDTH, 3)\n",
    "    inputs = layers.Input(shape=(TIME_STEPS, HEIGHT, WIDTH, 3))\n",
    "\n",
    "    # TimeDistributed layer to apply the base model to each frame\n",
    "    base_model = keras.applications.Xception(weights='imagenet', include_top=False, pooling='avg')\n",
    "    # For inference, we don't need to set trainable, but if you plan to retrain, you can set accordingly\n",
    "    # base_model.trainable = False\n",
    "\n",
    "    # Apply TimeDistributed wrapper\n",
    "    x = layers.TimeDistributed(base_model)(inputs)\n",
    "    # x shape: (batch_size, TIME_STEPS, 2048)\n",
    "\n",
    "    # LSTM layer\n",
    "    x = layers.LSTM(lstm_hidden_size)(x)\n",
    "\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Load the model architecture\n",
    "model = build_model()\n",
    "# Load weights into the model\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Image Processing Function (now processes the entire image as a frame) ---\n",
    "def extract_face_from_image(image_path, target_height=HEIGHT, target_width=WIDTH):\n",
    "    \"\"\"\n",
    "    Loads an image from the given path, resizes it to target dimensions,\n",
    "    and returns the preprocessed image array.\n",
    "    Face detection is skipped; the entire image is treated as the input frame.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image file.\n",
    "        target_height (int): Desired height for the processed image.\n",
    "        target_width (int): Desired width for the processed image.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Preprocessed image array (HEIGHT, WIDTH, 3) or a black\n",
    "                       image array if an error occurs during loading.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the image using OpenCV\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Error: Image not found at {image_path}\")\n",
    "        # Convert BGR (OpenCV default) to RGB (for Keras)\n",
    "        frame_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image '{image_path}': {e}\")\n",
    "        # Return a black image if loading fails\n",
    "        return np.zeros((target_height, target_width, 3), dtype=np.float32)\n",
    "\n",
    "    # Resize the entire image to target dimensions\n",
    "    # Using PIL for resizing as it's often used with preprocess_input\n",
    "    image_pil = Image.fromarray(frame_rgb)\n",
    "    resized_image = image_pil.resize((target_width, target_height))\n",
    "\n",
    "    # Convert back to numpy array and preprocess for the Xception model\n",
    "    image_array = np.array(resized_image)\n",
    "    image_array = preprocess_input(image_array) # Xception specific preprocessing\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'data/image.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the preprocessed single frame from the image file\n",
    "single_frame_array = extract_face_from_image(image_path, target_height=HEIGHT, target_width=WIDTH)\n",
    "\n",
    "# Replicate the single preprocessed frame TIME_STEPS (30) times\n",
    "# This creates a sequence of identical frames: (TIME_STEPS, HEIGHT, WIDTH, 3)\n",
    "sequence_of_frames = np.array([single_frame_array] * TIME_STEPS)\n",
    "\n",
    "# Add the batch dimension: (1, TIME_STEPS, HEIGHT, WIDTH, 3)\n",
    "input_for_prediction = np.expand_dims(sequence_of_frames, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
